{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "torch.set_printoptions(edgeitems=500)\n",
    "\n",
    "# seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data class info:\n",
    "class 0: without autism associations\n",
    "class 1: autism genes\n",
    "class 2: 0.75 confidence\n",
    "class 3: 0.5 confidence\n",
    "class 4: unlabeled nodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10455\\OneDrive - Queen's University\\Queens\\CISC867\\PANDA\\src\\read_data.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  autism_df['label'][autism_df['confidence'] == 0.5] = 3\n"
     ]
    }
   ],
   "source": [
    "from src import read_data\n",
    "\n",
    "data = read_data.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(edge_index=[2, 811236], num_classes=25, test_mask=[23472], train_mask=[23472], x=[23472, 23472], y=[23472])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n",
      "Average node degree: 34.56\n"
     ]
    }
   ],
   "source": [
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "# dataset = data\n",
    "# data.train_mask = data.y >= 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([23472])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1376)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(459)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.test_mask.sum()\n",
    "# data.test_mask = data.y >= 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1376])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[data.train_mask].shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([459])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[data.test_mask].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# from torch_geometric.data import DataLoader\n",
    "#\n",
    "# loader = DataLoader(data, batch_size=32, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# data_list = [data]\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# dataset = DataLoader(data_list)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# dataset.num_node_features = data.num_node_features\n",
    "# dataset.num_classes = data.num_classes\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization Model Using Tensorboard Command\n",
    "commandline run tensorboard\n",
    "```\n",
    "cd src\n",
    "tensorboard --logdir log\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (conv1): GATConv(23472, 8, heads=8)\n",
      "  (conv2): GATConv(64, 25, heads=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "from GAT import GAT\n",
    "model = GAT(data)\n",
    "print(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Running on GPU or CPU\n",
    "use_GPU = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and use_GPU else 'cpu')\n",
    "model, data = model.to(device), data.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270. Loss: 1.0165. Train accuracy: 0.6025. Test accuracy: 0.6013\n",
      "Epoch 280. Loss: 1.0062. Train accuracy: 0.6032. Test accuracy: 0.6013\n",
      "Epoch 290. Loss: 1.0148. Train accuracy: 0.6032. Test accuracy: 0.6013\n",
      "Epoch 300. Loss: 0.9846. Train accuracy: 0.6010. Test accuracy: 0.6013\n",
      "Epoch 310. Loss: 0.9964. Train accuracy: 0.6010. Test accuracy: 0.6013\n",
      "Epoch 320. Loss: 0.9684. Train accuracy: 0.6025. Test accuracy: 0.6013\n",
      "Epoch 330. Loss: 0.9860. Train accuracy: 0.6039. Test accuracy: 0.6013\n",
      "Epoch 340. Loss: 0.9709. Train accuracy: 0.6039. Test accuracy: 0.6013\n",
      "Epoch 350. Loss: 0.9769. Train accuracy: 0.6025. Test accuracy: 0.6013\n",
      "Epoch 360. Loss: 0.9814. Train accuracy: 0.6047. Test accuracy: 0.6013\n",
      "Epoch 370. Loss: 0.9449. Train accuracy: 0.6047. Test accuracy: 0.6013\n",
      "Epoch 380. Loss: 0.9762. Train accuracy: 0.6047. Test accuracy: 0.6013\n",
      "Epoch 390. Loss: 0.9705. Train accuracy: 0.6061. Test accuracy: 0.6013\n",
      "Epoch 400. Loss: 0.9476. Train accuracy: 0.6061. Test accuracy: 0.6013\n",
      "Epoch 0. Loss: 3.2190. Train accuracy: 0.5981. Test accuracy: 0.6013\n",
      "Epoch 10. Loss: 2.7763. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 20. Loss: 2.0436. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 30. Loss: 1.5661. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 40. Loss: 1.3767. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 50. Loss: 1.2719. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 60. Loss: 1.2442. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 70. Loss: 1.1924. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 80. Loss: 1.1834. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 90. Loss: 1.1456. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 100. Loss: 1.1361. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 110. Loss: 1.1003. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 120. Loss: 1.1052. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 130. Loss: 1.0975. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 140. Loss: 1.0826. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 150. Loss: 1.0848. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 160. Loss: 1.0796. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 170. Loss: 1.0814. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 180. Loss: 1.0665. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 190. Loss: 1.0709. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 200. Loss: 1.0651. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 210. Loss: 1.0576. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 220. Loss: 1.0553. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 230. Loss: 1.0515. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 240. Loss: 1.0557. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 250. Loss: 1.0522. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 260. Loss: 1.0589. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 270. Loss: 1.0495. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 280. Loss: 1.0481. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 290. Loss: 1.0495. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 300. Loss: 1.0413. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 310. Loss: 1.0466. Train accuracy: 0.6003. Test accuracy: 0.6013\n",
      "Epoch 320. Loss: 1.0416. Train accuracy: 0.6003. Test accuracy: 0.6013\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-54-a39c71f6ef0d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[0mwriter\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSummaryWriter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"./log/\"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrftime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"%Y%m%d-%H%M%S\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_train\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwriter\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch_num\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m400\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight_decay\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4e-4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-54-a39c71f6ef0d>\u001B[0m in \u001B[0;36mmodel_train\u001B[1;34m(dataset, writer, model, epoch_num, lr, weight_decay)\u001B[0m\n\u001B[0;32m     65\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;36m20\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m             \u001B[0mname\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'epoch'\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m             \u001B[0mwriter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd_embedding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membedding\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mglobal_step\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtag\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetadata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\AI-CUDA\\lib\\site-packages\\tensorboardX\\writer.py\u001B[0m in \u001B[0;36madd_embedding\u001B[1;34m(self, mat, metadata, label_img, global_step, tag, metadata_header)\u001B[0m\n\u001B[0;32m   1043\u001B[0m             \u001B[0mmake_sprite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabel_img\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1044\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mmat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'mat should be 2D, where mat.size(0) is the number of data points'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1045\u001B[1;33m         \u001B[0mmake_mat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmat\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1046\u001B[0m         \u001B[1;31m# new funcion to append to the config file a new embedding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1047\u001B[0m         append_pbtxt(metadata, label_img,\n",
      "\u001B[1;32m~\\anaconda3\\envs\\AI-CUDA\\lib\\site-packages\\tensorboardX\\embedding.py\u001B[0m in \u001B[0;36mmake_mat\u001B[1;34m(matlist, save_path)\u001B[0m\n\u001B[0;32m    117\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmatlist\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    118\u001B[0m             \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 119\u001B[1;33m             \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'\\t'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m'\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    120\u001B[0m     \u001B[0mmaybe_upload_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnamed_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def model_test(loader, model, is_validation=False, is_training=False):\n",
    "    ''' Testing Code of the Model '''\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            emb, pred = model(data.x, data.edge_index)\n",
    "            pred = pred.argmax(dim=1)\n",
    "            label = data.y\n",
    "\n",
    "        if is_training:\n",
    "            mask = data.val_mask if is_validation else data.train_mask\n",
    "        else: # testing\n",
    "            mask = data.val_mask if is_validation else data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = data.y[mask]\n",
    "\n",
    "        correct += pred.eq(label).sum().item()\n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        if is_training:\n",
    "            total += torch.sum(data.train_mask).item()\n",
    "        else:\n",
    "            total += torch.sum(data.test_mask).item()\n",
    "    return correct / total\n",
    "\n",
    "def model_train(dataset, writer, model, epoch_num, lr, weight_decay):\n",
    "    ''' Training code of the model '''\n",
    "    test_loader = loader = DataLoader(dataset, shuffle=False)\n",
    "\n",
    "    # Optimizer\n",
    "    opt = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=0.9)\n",
    "    # opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # visualize the model architecture in tensorboard\n",
    "    # writer.add_graph(model, ( data.x, data.edge_index ))\n",
    "\n",
    "    # Training:\n",
    "    for epoch in range(epoch_num + 1):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            #print(batch.train_mask, '----')\n",
    "            opt.zero_grad()\n",
    "            embedding, pred = model(batch.x, batch.edge_index)\n",
    "            label = batch.y\n",
    "            pred = pred[batch.train_mask]\n",
    "            label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        writer.add_scalar(\"loss\", total_loss, epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            train_acc = model_test(test_loader, model, is_training=True)\n",
    "            test_acc = model_test(test_loader, model, is_training=False)\n",
    "            print(\"Epoch {}. Loss: {:.4f}. Train accuracy: {:.4f}. Test accuracy: {:.4f}\".format(\n",
    "                epoch, total_loss, train_acc, test_acc))\n",
    "            writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            name = 'epoch' + str(epoch)\n",
    "            writer.add_embedding(embedding, global_step=epoch, tag=name, metadata=batch.y)\n",
    "\n",
    "    return model\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "model = model_train([data], writer, model, epoch_num=400, lr=0.01, weight_decay=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}