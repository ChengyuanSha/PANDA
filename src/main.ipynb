{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "torch.set_printoptions(edgeitems=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import read_data\n",
    "\n",
    "data = read_data.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(edge_index=[2, 21398], num_classes=2, test_mask=[1835], train_mask=[1835], x=[1835, 1835], y=[1835])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# dataset = data\n",
    "# data.train_mask = data.y >= 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# data.test_mask = data.y >= 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# from torch_geometric.data import DataLoader\n",
    "#\n",
    "# loader = DataLoader(data, batch_size=32, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_list = [data]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dataset = DataLoader(data_list, batch_size=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dataset.num_node_features = data.num_node_features\n",
    "dataset.num_classes = data.num_classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNStack(\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConv(1835, 128)\n",
      "    (1): GCNConv(128, 64)\n",
      "    (2): GCNConv(64, 64)\n",
      "  )\n",
      "  (lns): ModuleList(\n",
      "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (post_mp): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.25, inplace=False)\n",
      "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from general_GNN import GNNStack\n",
    "\n",
    "model = GNNStack(data.num_node_features, hidden_dim1=128, hidden_dim2=64, output_dim=data.num_classes)\n",
    "print(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Running on GPU or CPU\n",
    "use_GPU = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and use_GPU else 'cpu')\n",
    "model, data = model.to(device), data.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def test(loader, model, is_validation=False):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            emb, pred = model(data.x, data.edge_index)\n",
    "            pred = pred.argmax(dim=1)\n",
    "            label = data.y\n",
    "\n",
    "        mask = data.val_mask if is_validation else data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = data.y[mask]\n",
    "\n",
    "        correct += pred.eq(label).sum().item()\n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        total += torch.sum(data.test_mask).item()\n",
    "    return correct / total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def train(dataset, writer, model, epoch_num):\n",
    "    test_loader = loader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "    # build model\n",
    "    # model = GNNStack(max(data.num_node_features, 1), 32, data.num_classes)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "    #writer.add_graph(model, ( data.x, data.edge_index, torch.zeros(data.train_mask.shape[0], device=torch.device('cuda')) ))\n",
    "    # train\n",
    "    for epoch in range(epoch_num + 1):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            #print(batch.train_mask, '----')\n",
    "            opt.zero_grad()\n",
    "            embedding, pred = model(batch.x, batch.edge_index)\n",
    "            label = batch.y\n",
    "            pred = pred[batch.train_mask]\n",
    "            label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        writer.add_scalar(\"loss\", total_loss, epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_acc = test(test_loader, model)\n",
    "            print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(\n",
    "                epoch, total_loss, test_acc))\n",
    "            writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            name = 'epoch' + str(epoch)\n",
    "            writer.add_embedding(embedding, global_step=epoch, tag=name, metadata=batch.y)\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization using tensorboard\n",
    "commandline run tensorboard\n",
    "```\n",
    "cd src\n",
    "tensorboard --logdir log\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.6776. Test accuracy: 0.6104\n",
      "Epoch 10. Loss: 0.6136. Test accuracy: 0.5640\n",
      "Epoch 20. Loss: 0.5720. Test accuracy: 0.5967\n",
      "Epoch 30. Loss: 0.4558. Test accuracy: 0.5477\n",
      "Epoch 40. Loss: 0.3965. Test accuracy: 0.5613\n",
      "Epoch 50. Loss: 0.3456. Test accuracy: 0.5450\n",
      "Epoch 60. Loss: 0.3016. Test accuracy: 0.5368\n",
      "Epoch 70. Loss: 0.2670. Test accuracy: 0.5613\n",
      "Epoch 80. Loss: 0.2540. Test accuracy: 0.4959\n",
      "Epoch 90. Loss: 0.2622. Test accuracy: 0.5313\n",
      "Epoch 100. Loss: 0.2081. Test accuracy: 0.5313\n",
      "Epoch 110. Loss: 0.2030. Test accuracy: 0.5668\n",
      "Epoch 120. Loss: 0.2004. Test accuracy: 0.5695\n",
      "Epoch 130. Loss: 0.1440. Test accuracy: 0.5695\n",
      "Epoch 140. Loss: 0.1268. Test accuracy: 0.5695\n",
      "Epoch 150. Loss: 0.1053. Test accuracy: 0.5586\n",
      "Epoch 160. Loss: 0.1155. Test accuracy: 0.5613\n",
      "Epoch 170. Loss: 0.1024. Test accuracy: 0.5450\n",
      "Epoch 180. Loss: 0.0771. Test accuracy: 0.5722\n",
      "Epoch 190. Loss: 0.1318. Test accuracy: 0.5613\n",
      "Epoch 200. Loss: 0.1008. Test accuracy: 0.5640\n",
      "Epoch 210. Loss: 0.0494. Test accuracy: 0.5531\n",
      "Epoch 220. Loss: 0.0409. Test accuracy: 0.5422\n",
      "Epoch 230. Loss: 0.0439. Test accuracy: 0.5695\n",
      "Epoch 240. Loss: 0.0483. Test accuracy: 0.5504\n",
      "Epoch 250. Loss: 0.0471. Test accuracy: 0.5531\n",
      "Epoch 260. Loss: 0.0718. Test accuracy: 0.5559\n",
      "Epoch 270. Loss: 0.0335. Test accuracy: 0.5613\n",
      "Epoch 280. Loss: 0.0290. Test accuracy: 0.5586\n",
      "Epoch 290. Loss: 0.0345. Test accuracy: 0.5695\n",
      "Epoch 300. Loss: 0.0304. Test accuracy: 0.5831\n",
      "Epoch 310. Loss: 0.0244. Test accuracy: 0.5831\n",
      "Epoch 320. Loss: 0.0222. Test accuracy: 0.5777\n",
      "Epoch 330. Loss: 0.0159. Test accuracy: 0.5749\n",
      "Epoch 340. Loss: 0.0224. Test accuracy: 0.5640\n",
      "Epoch 350. Loss: 0.0153. Test accuracy: 0.5531\n",
      "Epoch 360. Loss: 0.0226. Test accuracy: 0.5695\n",
      "Epoch 370. Loss: 0.0117. Test accuracy: 0.5722\n",
      "Epoch 380. Loss: 0.0156. Test accuracy: 0.5640\n",
      "Epoch 390. Loss: 0.0186. Test accuracy: 0.5450\n",
      "Epoch 400. Loss: 0.0111. Test accuracy: 0.5613\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "model = train([data], writer, model, epoch_num=400)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}