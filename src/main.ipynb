{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.data import DataLoader\n",
    "import random\n",
    "\n",
    "torch.set_printoptions(edgeitems=500)\n",
    "\n",
    "# seed for reproducibility\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset info:\n",
    "class 0: without autism associations\n",
    "class 1: autism genes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import read_data\n",
    "\n",
    "data = read_data.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[23472, 23472], edge_index=[2, 811236], y=[23472], train_mask=[23472], test_mask=[23472], val_mask=[23472], num_classes=23)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n",
      "Average node degree: 34.56\n"
     ]
    }
   ],
   "source": [
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "# dataset = data\n",
    "# data.train_mask = data.y >= 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([23472])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total nodes\n",
    "data.train_mask.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1284)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of training samples\n",
    "data.train_mask.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(276)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of testing samples\n",
    "data.test_mask.sum()\n",
    "# data.test_mask = data.y >= 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(275)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of validation samples\n",
    "data.val_mask.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1284])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[data.train_mask].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([276])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[data.test_mask].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Visualization of the Model Using Tensorboard Command\n",
    "commandline run tensorboard\n",
    "```\n",
    "cd src\n",
    "tensorboard --logdir log\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNStack(\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConv(23472, 128)\n",
      "    (1): GCNConv(128, 64)\n",
      "    (2): GCNConv(64, 32)\n",
      "  )\n",
      "  (lns): ModuleList(\n",
      "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (post_mp): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (1): Linear(in_features=32, out_features=23, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "from GCN import GCNStack\n",
    "\n",
    "model = GCNStack(data.num_node_features, hidden_dim1=128, hidden_dim2=64, hidden_dim3=32, output_dim=data.num_classes, dropout=0.5)\n",
    "print(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Running on GPU or CPU\n",
    "use_GPU = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and use_GPU else 'cpu')\n",
    "model, data = model.to(device), data.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 3.1088. Train accuracy: 0.7679. Validation accuracy: 0.7200\n",
      "Epoch 1. Loss: 2.8451. Train accuracy: 0.8294. Validation accuracy: 0.8036\n",
      "Epoch 2. Loss: 2.6472. Train accuracy: 0.8442. Validation accuracy: 0.8327\n",
      "Epoch 3. Loss: 2.5435. Train accuracy: 0.8497. Validation accuracy: 0.8364\n",
      "Epoch 4. Loss: 2.4562. Train accuracy: 0.8536. Validation accuracy: 0.8400\n",
      "Epoch 5. Loss: 2.4181. Train accuracy: 0.8567. Validation accuracy: 0.8400\n",
      "Epoch 6. Loss: 2.3826. Train accuracy: 0.8583. Validation accuracy: 0.8400\n",
      "Epoch 7. Loss: 2.3652. Train accuracy: 0.8614. Validation accuracy: 0.8436\n",
      "Epoch 8. Loss: 2.3265. Train accuracy: 0.8621. Validation accuracy: 0.8436\n",
      "Epoch 9. Loss: 2.3005. Train accuracy: 0.8645. Validation accuracy: 0.8473\n",
      "Epoch 10. Loss: 2.2810. Train accuracy: 0.8668. Validation accuracy: 0.8473\n",
      "Epoch 11. Loss: 2.2707. Train accuracy: 0.8676. Validation accuracy: 0.8473\n",
      "Epoch 12. Loss: 2.2506. Train accuracy: 0.8684. Validation accuracy: 0.8473\n",
      "Epoch 13. Loss: 2.2539. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 14. Loss: 2.2416. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 15. Loss: 2.2181. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 16. Loss: 2.2105. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 17. Loss: 2.1800. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 18. Loss: 2.1635. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 19. Loss: 2.1676. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 20. Loss: 2.1593. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 21. Loss: 2.1413. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 22. Loss: 2.1487. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 23. Loss: 2.1526. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 24. Loss: 2.1157. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 25. Loss: 2.1258. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 26. Loss: 2.1011. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 27. Loss: 2.1002. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 28. Loss: 2.0887. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 29. Loss: 2.0870. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 30. Loss: 2.0513. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 31. Loss: 2.0584. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 32. Loss: 2.0366. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 33. Loss: 2.0192. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 34. Loss: 2.0067. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 35. Loss: 2.0178. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 36. Loss: 2.0192. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 37. Loss: 1.9772. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 38. Loss: 1.9945. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 39. Loss: 1.9884. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 40. Loss: 1.9883. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 41. Loss: 1.9506. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 42. Loss: 1.9328. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 43. Loss: 1.9184. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 44. Loss: 1.9398. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 45. Loss: 1.9228. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 46. Loss: 1.9051. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 47. Loss: 1.9144. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 48. Loss: 1.8995. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 49. Loss: 1.8871. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 50. Loss: 1.8575. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 51. Loss: 1.8471. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 52. Loss: 1.8372. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 53. Loss: 1.8624. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 54. Loss: 1.8603. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 55. Loss: 1.8125. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 56. Loss: 1.8232. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 57. Loss: 1.7983. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 58. Loss: 1.8051. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 59. Loss: 1.8067. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 60. Loss: 1.8087. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 61. Loss: 1.7695. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 62. Loss: 1.7602. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 63. Loss: 1.7663. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 64. Loss: 1.7532. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 65. Loss: 1.7341. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 66. Loss: 1.7250. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 67. Loss: 1.7271. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 68. Loss: 1.7389. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 69. Loss: 1.7020. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 70. Loss: 1.7015. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 71. Loss: 1.7003. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 72. Loss: 1.6862. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 73. Loss: 1.7005. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 74. Loss: 1.6727. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 75. Loss: 1.6650. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 76. Loss: 1.6393. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 77. Loss: 1.6364. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 78. Loss: 1.6450. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 79. Loss: 1.6211. Train accuracy: 0.8692. Validation accuracy: 0.8473\n",
      "Epoch 80. Loss: 1.6323. Train accuracy: 0.8692. Validation accuracy: 0.8473\n"
     ]
    }
   ],
   "source": [
    "def model_test(loader, model, is_validation=False, is_training=False):\n",
    "    ''' Testing Code of the Model '''\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            emb, pred = model(data.x, data.edge_index)\n",
    "            pred = pred.argmax(dim=1)\n",
    "\n",
    "        if is_training:\n",
    "            mask = data.train_mask\n",
    "        elif is_validation:\n",
    "            mask = data.val_mask\n",
    "        else: # testing\n",
    "            mask = data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = data.y[mask]\n",
    "        # testing code\n",
    "        # training_status = 'Training' if is_training else 'Testing'\n",
    "        # print(training_status, '$$pred', pred)\n",
    "        # print(training_status, '%%label', label)\n",
    "        correct += pred.eq(label).sum().item()\n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        if is_training:\n",
    "            total += torch.sum(data.train_mask).item()\n",
    "        elif is_validation:\n",
    "            total += torch.sum(data.val_mask).item()\n",
    "        else:\n",
    "            total += torch.sum(data.test_mask).item()\n",
    "    return correct / total, pred, label\n",
    "\n",
    "def model_train(dataset, writer, model, epoch_num, lr, weight_decay, momentum):\n",
    "    ''' Training code of the model '''\n",
    "    test_loader = loader = DataLoader(dataset, shuffle=False)\n",
    "\n",
    "    # Optimizer\n",
    "    # opt = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # visualize the model architecture in tensorboard\n",
    "    # writer.add_graph(model, ( data.x, data.edge_index ))\n",
    "\n",
    "    # Training:\n",
    "    for epoch in range(epoch_num + 1):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            #print(batch.train_mask, '----')\n",
    "            opt.zero_grad()\n",
    "            embedding, pred = model(batch.x, batch.edge_index)\n",
    "            label = batch.y\n",
    "            pred = pred[batch.train_mask]\n",
    "            label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        writer.add_scalar(\"loss\", total_loss, epoch)\n",
    "\n",
    "        # if epoch % 5 == 0:\n",
    "        train_acc, _, _ = model_test(test_loader, model, is_training=True)\n",
    "        validation_acc, _, _= model_test(test_loader, model, is_training=False, is_validation=True)\n",
    "        print(\"Epoch {}. Loss: {:.4f}. Train accuracy: {:.4f}. Validation accuracy: {:.4f}\".format(\n",
    "            epoch, total_loss, train_acc, validation_acc))\n",
    "        writer.add_scalar(\"validation accuracy\", validation_acc, epoch)\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            name = 'epoch' + str(epoch)\n",
    "            writer.add_embedding(embedding, global_step=epoch, tag=name, metadata=batch.y)\n",
    "\n",
    "    return model\n",
    "\n",
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "model_trained = model_train([data], writer, model, epoch_num=80, lr=0.0001, weight_decay=0.00001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "test_acc, pred, label = model_test( DataLoader([data], shuffle=False), model_trained, is_training=False, is_validation=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8840579710144928"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "pred_np = pred.cpu().detach().numpy()\n",
    "label_np = label.cpu().detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,  recall_score, precision_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9384615384615385"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(pred_np, label_np, average='weighted')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(pred_np, label_np, average='weighted')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8840579710144928"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(pred_np, label_np, average='weighted')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# save model\n",
    "# torch.save(model_trained, f='pretrained_model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Precision @ k plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# change k here\n",
    "num_of_k = 8000\n",
    "\n",
    "def compute_top_k(loader, model):\n",
    "    \"\"\" Testing Code of the Model \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            emb, pred = model(data.x, data.edge_index)\n",
    "            prob = F.softmax(pred, dim=1).max(dim=1)[0]\n",
    "            pred = pred.argmax(dim=1)\n",
    "            # compute top k with the highest probability\n",
    "            val, idx = torch.topk(prob, k=num_of_k, dim=0)\n",
    "\n",
    "    return  pred, val, idx\n",
    "\n",
    "pred, val, idx = compute_top_k( DataLoader([data], shuffle=False), model_trained)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "positive_position = read_data.get_autism_position()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "idx = idx.tolist()\n",
    "positive_position = positive_position.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "intersect = set(idx).intersection(positive_position)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0175"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the paper formula to calculate\n",
    "len(intersect) / num_of_k"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "((1000, 0.029),\n (2000, 0.0185),\n (3000, 0.017),\n (4000, 0.01825),\n (5000, 0.0168),\n (6000, 0.017167),\n (7000, 0.017114),\n (8000, 0.0175))"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coordinates:\n",
    "(1000, 0.029), (2000, 0.0185) , (3000, 0.017), (4000, 0.01825) , (5000, 0.0168),  (6000, 0.017167), (7000, 0.017114), (8000, 0.0175)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}